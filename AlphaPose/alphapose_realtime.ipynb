{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e081bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from opencv-python) (1.16.6)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3909f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gluoncv\n",
      "  Using cached gluoncv-0.10.5-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (1.1.5)\n",
      "Requirement already satisfied: requests in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (2.18.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (8.4.0)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting autocfg\n",
      "  Using cached autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (3.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (1.5.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (4.62.3)\n",
      "Collecting yacs\n",
      "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (1.16.6)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from gluoncv) (4.5.5.64)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from autocfg->gluoncv) (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from matplotlib->gluoncv) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from matplotlib->gluoncv) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from matplotlib->gluoncv) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from matplotlib->gluoncv) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from pandas->gluoncv) (2021.3)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from portalocker->gluoncv) (303)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from requests->gluoncv) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from requests->gluoncv) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from requests->gluoncv) (1.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\wjd72\\anaconda3\\envs\\py36\\lib\\site-packages (from tqdm->gluoncv) (0.4.4)\n",
      "Installing collected packages: pyyaml, yacs, portalocker, autocfg, gluoncv\n",
      "Successfully installed autocfg-0.0.8 gluoncv-0.10.5 portalocker-2.4.0 pyyaml-6.0 yacs-0.1.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c8642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse, time, logging, os, math, tqdm, cv2\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gluoncv as gcv\n",
    "from gluoncv import data\n",
    "from gluoncv.data import mscoco\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.data.transforms.pose import detector_to_alpha_pose,heatmap_to_coord_alpha_pose, detector_to_simple_pose, heatmap_to_coord\n",
    "from gluoncv.utils.viz import cv_plot_image, cv_plot_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc062bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "# detector_name = \"ssd_512_mobilenet1.0_coco\"\n",
    "detector_name= \"yolo3_mobilenet1.0_coco\"\n",
    "detector = get_model(detector_name, pretrained=True, ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8167f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.reset_class(classes=['person'], reuse_weights={'person':'person'})\n",
    "detector.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ef0fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimators = get_model('simple_pose_resnet18_v1b', pretrained='ccd24037', ctx=ctx)\n",
    "estimators = get_model('alpha_pose_resnet101_v1b_coco', pretrained=True, ctx=ctx)\n",
    "estimators.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5408ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# time.sleep(1)  ### letting the camera autofocus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838e19a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dde9f2a",
   "metadata": {},
   "source": [
    "# Realtime-AlphaPose 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c18089",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "\n",
    "# used to record the time when we processed last frame\n",
    "prev_frame_time = 0\n",
    " \n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n",
    "\n",
    "\n",
    "while cv2.waitKey(33) < 0:\n",
    "    ret, frame = capture.read()\n",
    "    frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n",
    "#     x, frame = data.transforms.presets.yolo.load_test(frame, short=512)\n",
    "#     x, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=350)\n",
    "    x, frame = gcv.data.transforms.presets.yolo.transform_test(frame, short=512, max_size=350)\n",
    "    x = x.as_in_context(ctx)\n",
    "    class_IDs, scores, bounding_boxs = detector(x)\n",
    "\n",
    "    pose_input, upscale_bbox = detector_to_alpha_pose(frame, class_IDs, scores, bounding_boxs,\n",
    "                                                       output_shape=(128, 96), ctx=ctx)\n",
    "    \n",
    "    \n",
    "#     if len(upscale_bbox) > 0:\n",
    "#         predicted_heatmap = estimators(pose_input)\n",
    "#         pred_coords, confidence = heatmap_to_coord_alpha_pose(predicted_heatmap, upscale_bbox)\n",
    "\n",
    "#         img = cv_plot_keypoints(frame, pred_coords, confidence, class_IDs, bounding_boxs, scores,\n",
    "#                                 box_thresh=0.5, keypoint_thresh=0.2)\n",
    "        \n",
    "#         print(pred_coords)\n",
    "\n",
    "\n",
    "    # font which we will be using to display FPS\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    # time when we finish processing for this frame\n",
    "    new_frame_time = time.time()\n",
    "\n",
    "\n",
    "    # Calculating the fps\n",
    " \n",
    "    # fps will be number of frame processed in given time frame\n",
    "    # since their will be most of time error of 0.001 second\n",
    "    # we will be subtracting it to get more accurate result\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    " \n",
    "    # converting the fps into integer\n",
    "    fps = int(fps)\n",
    " \n",
    "    # converting the fps to string so that we can display it on frame\n",
    "    # by using putText function\n",
    "    fps = str(fps)\n",
    " \n",
    "    # putting the FPS count on the frame\n",
    "    cv2.putText(frame, fps, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    " \n",
    "    # press 'Q' if you want to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"VideoFrame\", frame)\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871cb40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " [[[[-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]\n",
       "    [-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]\n",
       "    [-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]\n",
       "    ...\n",
       "    [-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]\n",
       "    [-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]\n",
       "    [-0.406 -0.406 -0.406 ... -0.406 -0.406 -0.406]]\n",
       " \n",
       "   [[-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]\n",
       "    [-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]\n",
       "    [-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]\n",
       "    ...\n",
       "    [-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]\n",
       "    [-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]\n",
       "    [-0.457 -0.457 -0.457 ... -0.457 -0.457 -0.457]]\n",
       " \n",
       "   [[-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]\n",
       "    [-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]\n",
       "    [-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]\n",
       "    ...\n",
       "    [-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]\n",
       "    [-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]\n",
       "    [-0.48  -0.48  -0.48  ... -0.48  -0.48  -0.48 ]]]]\n",
       " <NDArray 1x3x128x96 @cpu(0)>,\n",
       " array([[103.,  81., 349., 261.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_to_alpha_pose(frame, class_IDs, scores, bounding_boxs,\n",
    "                                                       output_shape=(128, 96), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bbca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7941aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667f65a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
